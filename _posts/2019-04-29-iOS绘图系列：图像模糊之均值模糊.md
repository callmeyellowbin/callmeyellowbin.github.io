### 零. 写在前面

最近的需求是做图像处理相关的，需要做出一个高斯模糊的效果，但是博客搜了一下，[参考文章](https://www.jianshu.com/p/e800d4935f2c)全部是代码，没有解释为什么，看得我一脸懵逼，后面自己收集了相关的材料，整理了一下，发现处理的方法其实不是高斯模糊，而是最简单的均值模糊，所以在这篇文章解释一下均值模糊的原理。

### 一. 模糊的简介

模糊，即在图像中，每一个像素都取了周边像素的平均值，如下图，设一张图片的像素值中间像素为2，周边像素均为1，如果中间点取周围点的平均值，就会变成1，在数值上产生了平滑效果，而在图形上，则产生了模糊效果，即中间的点失去了细节。

![正常像素](https://upload-images.jianshu.io/upload_images/8407639-560ee98204de9a82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![模糊像素](https://upload-images.jianshu.io/upload_images/8407639-2aa235e6cffb0f06.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 二. 卷积核

如何使中间的点变成1？这时候我们需要引入`卷积核（Convolution kernel）`的概念。

卷积是像素单位的操作，即对每个像素都要执行同样的算法，而一个核可以看做一个二维的网格数据，图像也可以看做一个二维的网格数据，对一个图像应用`核（kernel）`可以想象成把一个小格子（核）平铺在大格子（图像）上面。

如下图所示，最底层为原图像，中间层为核，最上层为处理后的图像。在进行卷积运算时，kernel的中心值会覆盖在待转换的像素上面，然后将kernel的每个值与其下方的像素值相乘，最后将所有结果相加，相加后的结果就是新的像素强度。

![](https://upload-images.jianshu.io/upload_images/8407639-784bb3681a18a7b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

需要注意的是，核的行和列的数量必须为奇数，否则将会找不到中心点。

### 三. 均值模糊

均值模糊，也叫领域平均、均值滤波，是图像平滑去噪算法中最简单的一种，它会将原图中的一个像素值和它周围临近的N个像素值相加，然后求得平均值，获得新图中该点的像素值，数学公式为：$g(i,j)=\sum{\frac{f(i,j)}{N}}$，其中，N为kernel的像素个数。

如：3*3的kernel为：

![](https://upload-images.jianshu.io/upload_images/8407639-893c0b7897e1318a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

kernel的width和height越大，模糊效果越明显。

### 四. 相关API

vImage为这种权重相同的kernel提供了专门的api：

```
vImage_Error error = vImageBoxConvolve_ARGB8888(src,
                                  dest,
                                   tempBuffer,
                                   srcOffsetToROI_X,
                                   srcOffsetToROI_Y,
                                   kernel_height,
                                   kernel_width,
                                   backgroundColor,
                                   flags);
```

各参数意义如下：

- vImage_Buffer *src：原图的buffer类型

- vImage_Buffer * dest：输出的buffer类型

- void *tempBuffer：临时的buffer，可置空

- vImagePixelCount  srcOffsetToROI_X：x轴方向的位移，相对于左上角像素

- vImagePixelCount  srcOffsetToROI_Y：y轴方向的位移，相对于左上角像素

- uint32_t kernel_height：kernel的高度，必须是奇数

- uint32_t kernel_width：kernel的宽度，必须是奇数

- Pixel_8888 backgroundColor：背景色

- vImage_Flags flags：标志位，kvImageEdgeExtend代表如果像素点缺失，则使用最近的像素点

### 五. API的调用

要调用均值模糊的API，可以分为以下步骤：

1. 通过CGImageRef获取inBuffer的width、height、rowBytes、data
2. 同样设置outBuffer的相关参数
3. 调用API，获得outBuffer
4. 根据outBuffer再转化为CGImageRef
5. 释放相关指针

```
- (void)_processGaussianImage:(UIImage *)image completedBlock:(void (^)(UIImage * _Nullable image))completeBlock {
    CGFloat blur = 0.5f;
    int boxSize = (int)(blur * 40);
    
    // 确保为奇数
    boxSize = boxSize - (boxSize % 2) + 1;
    
    CGImageRef imageRef = image.CGImage;
    vImage_Buffer inBuffer, outBuffer;
    vImage_Error error;
    void *pixelBuffer;
    
    // 从CGImage中获取数据
    CGDataProviderRef inProvider = CGImageGetDataProvider(imageRef);
    CFDataRef inBitmapData = CGDataProviderCopyData(inProvider);
    
    // 设置从CGImage获取对象的属性
    pixelBuffer = malloc(CGImageGetBytesPerRow(imageRef) * CGImageGetHeight(imageRef));
    
    outBuffer.width = inBuffer.width = CGImageGetWidth(imageRef);
    outBuffer.height = inBuffer.height = CGImageGetHeight(imageRef);
    outBuffer.rowBytes = inBuffer.rowBytes = CGImageGetBytesPerRow(imageRef);
    inBuffer.data = (void *)CFDataGetBytePtr(inBitmapData);
    outBuffer.data = pixelBuffer;
    
    // 均值模糊
    error = vImageBoxConvolve_ARGB8888(&inBuffer,
                                       &outBuffer,
                                       NULL,
                                       0,
                                       0,
                                       boxSize,
                                       boxSize,
                                       NULL,
                                       kvImageEdgeExtend);
    
    if (error) {
        NSLog(@"Error from convolution %ld", error);
    }
    
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    CGContextRef context = CGBitmapContextCreate(outBuffer.data, outBuffer.width, outBuffer.height, 8, outBuffer.rowBytes, colorSpace, CGImageGetBitmapInfo(imageRef));
    CGImageRef resultImageRef = CGBitmapContextCreateImage(context);
    UIImage *resultImage = [UIImage imageWithCGImage:resultImageRef];
    
    CGColorSpaceRelease(colorSpace);
    free(pixelBuffer);
    CFRelease(inBitmapData);
    CGColorSpaceRelease(colorSpace);
    CGImageRelease(resultImageRef);
    
    if (completeBlock) {
        completeBlock(resultImage);
    }
}
```

六. 参考文献

[Learning OpenCV with iOS： 图像模糊--线性滤波](https://www.jianshu.com/p/22c6774f830c)

[iOS中的vImage](https://xta0.me/2013/07/30/iOS-vImage.html)

[图像处理之vImage（二）——卷积](https://www.jianshu.com/p/725723be74c6)

[Apple Document](https://developer.apple.com/documentation/accelerate/1515945-vimageboxconvolve_argb8888?language=objc)